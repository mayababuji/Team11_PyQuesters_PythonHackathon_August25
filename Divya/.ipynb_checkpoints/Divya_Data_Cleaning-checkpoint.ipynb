{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a739d1-361f-4517-a586-9c96e383d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined all 25 files ,cleaned and saved to final_patients.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8bead6-e6d4-4a05-8dac-e3e989f68be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def combine_clean_save_patients(\n",
    "    folder_path=\"patients_data\",\n",
    "    file_pattern=\"HUPA*.csv\",\n",
    "    output_file=\"final_patients.csv\",\n",
    "    delimiter=\";\",\n",
    "    verbose=True\n",
    "):\n",
    "    # Step 1: Load existing cleaned file if it exists\n",
    "    if os.path.exists(output_file):\n",
    "        if verbose:\n",
    "            print(f\"üìÇ Existing file found: {output_file}\")\n",
    "        existing_df = pd.read_csv(output_file)\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "        if verbose:\n",
    "            print(\"üìÇ No existing file found. Starting fresh.\")\n",
    "\n",
    "    # Step 2: Load all matching CSV files from folder\n",
    "    file_list = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "    if verbose:\n",
    "        print(f\"üìÅ Found {len(file_list)} patient files\")\n",
    "\n",
    "    df_list = []\n",
    "    for file in file_list:\n",
    "        temp_df = pd.read_csv(file, delimiter=delimiter)\n",
    "        patient_id = os.path.basename(file).split(\".\")[0]\n",
    "        temp_df['patient_id'] = patient_id\n",
    "        df_list.append(temp_df)\n",
    "\n",
    "    # Step 3: Combine new batch\n",
    "    new_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Step 4: Reorder columns\n",
    "    cols = ['patient_id'] + [col for col in new_df.columns if col != 'patient_id']\n",
    "    new_df = new_df[cols]\n",
    "\n",
    "    # Step 5: Clean new data\n",
    "    new_df = new_df.drop_duplicates()\n",
    "    new_df = new_df.dropna(subset=['time', 'glucose'])\n",
    "    new_df['time'] = pd.to_datetime(new_df['time'], errors='coerce')\n",
    "    new_df = new_df.dropna(subset=['time'])\n",
    "    new_df = new_df.sort_values(by=['patient_id', 'time']).reset_index(drop=True)\n",
    "\n",
    "    # Step 6: Merge with existing data and deduplicate\n",
    "    combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    combined_df = combined_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Step 7: Save final cleaned file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    if verbose:\n",
    "        print(f\"‚úÖ Final cleaned data saved to: {output_file}\")\n",
    "        print(f\"üßÆ Total records: {len(combined_df)}\")\n",
    "        print(f\"üìä Columns: {combined_df.columns.tolist()}\")\n",
    "        print(\"üîç Sample rows:\")\n",
    "        print(combined_df.head().to_string(index=False))\n",
    "\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ba7b29-f7ba-4e9a-b5e6-e3e82cb39a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Existing file found: final_patients.csv\n",
      "üìÅ Found 25 patient files\n",
      "‚úÖ Final cleaned data saved to: final_patients.csv\n",
      "üßÆ Total records: 618784\n",
      "üìä Columns: ['patient_id', 'time', 'glucose', 'calories', 'heart_rate', 'steps', 'basal_rate', 'bolus_volume_delivered', 'carb_input']\n",
      "üîç Sample rows:\n",
      "patient_id                time  glucose  calories  heart_rate  steps  basal_rate  bolus_volume_delivered  carb_input\n",
      " HUPA0001P 2018-06-13 18:40:00    332.0    6.3595   82.322835   34.0    0.091667                     0.0         0.0\n",
      " HUPA0001P 2018-06-13 18:45:00    326.0    7.7280   83.740157    0.0    0.091667                     0.0         0.0\n",
      " HUPA0001P 2018-06-13 18:50:00    330.0    4.7495   80.525180    0.0    0.091667                     0.0         0.0\n",
      " HUPA0001P 2018-06-13 18:55:00    324.0    6.3595   89.129032   20.0    0.091667                     0.0         0.0\n",
      " HUPA0001P 2018-06-13 19:00:00    306.0    5.1520   92.495652    0.0    0.075000                     0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "df = combine_clean_save_patients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50829700-a976-438e-aa01-a257a5977e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned the final_patients file with the time colun seperated to date,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad21113a-14bc-46bd-8a51-a8483bd46643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Enriched Data Summary\n",
      "Total records: 618784\n",
      "Columns: ['patient_id', 'time', 'glucose', 'calories', 'heart_rate', 'steps', 'basal_rate', 'bolus_volume_delivered', 'carb_input', 'date', 'clock_time', 'hour', 'dayofweek']\n",
      "üîç Sample rows:\n",
      "patient_id                time  glucose  calories  heart_rate  steps  basal_rate  bolus_volume_delivered  carb_input       date clock_time  hour dayofweek\n",
      " HUPA0001P 2018-06-13 18:40:00    332.0    6.3595   82.322835   34.0    0.091667                     0.0         0.0 2018-06-13   18:40:00    18 Wednesday\n",
      " HUPA0001P 2018-06-13 18:45:00    326.0    7.7280   83.740157    0.0    0.091667                     0.0         0.0 2018-06-13   18:45:00    18 Wednesday\n",
      " HUPA0001P 2018-06-13 18:50:00    330.0    4.7495   80.525180    0.0    0.091667                     0.0         0.0 2018-06-13   18:50:00    18 Wednesday\n",
      " HUPA0001P 2018-06-13 18:55:00    324.0    6.3595   89.129032   20.0    0.091667                     0.0         0.0 2018-06-13   18:55:00    18 Wednesday\n",
      " HUPA0001P 2018-06-13 19:00:00    306.0    5.1520   92.495652    0.0    0.075000                     0.0         0.0 2018-06-13   19:00:00    19 Wednesday\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load cleaned data\n",
    "df_enriched = pd.read_csv(\"final_patients.csv\")\n",
    "\n",
    "# Step 2: Add enriched columns\n",
    "df_enriched['date'] = pd.to_datetime(df['time']).dt.date\n",
    "df_enriched['clock_time'] = pd.to_datetime(df['time']).dt.time\n",
    "df_enriched['hour'] = pd.to_datetime(df['time']).dt.hour\n",
    "df_enriched['dayofweek'] = pd.to_datetime(df['time']).dt.day_name()\n",
    "\n",
    "# Step 3: Save enriched version\n",
    "df_enriched.to_csv(\"final_patients_enriched.csv\", index=False)\n",
    "# Step 4: Preview enriched data\n",
    "print(\"üìä Enriched Data Summary\")\n",
    "print(f\"Total records: {len(df_enriched)}\")\n",
    "print(f\"Columns: {df_enriched.columns.tolist()}\")\n",
    "print(\"üîç Sample rows:\")\n",
    "print(df_enriched.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e4f3e-0ce8-4bd7-8a9d-7c39c90903a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename the T1DM_patient_sleep_demographics_with_race file column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0ad0de-d908-4e8b-b200-501a57af4cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id  age gender            race  avg_sleep_hours  sleep_quality  sleep_disturbances_pct\n",
      " HUPA0001P   34   Male           Other              6.3            4.5                      80\n",
      " HUPA0002P   49   Male        Hispanic              6.6            4.4                      40\n",
      " HUPA0003P   64   Male           Black              5.3            5.2                      70\n",
      " HUPA0004P   34 Female Native American              5.2            6.9                      60\n",
      " HUPA0005P   49   Male Native American              5.8            7.9                      30\n"
     ]
    }
   ],
   "source": [
    "# Load demographics data\n",
    "df_demo = pd.read_csv(os.path.join(\"patients_data\", \"T1DM_patient_sleep_demographics_with_race.csv\"))\n",
    "# renaming column nmaes\n",
    "rename_map = {\n",
    "    'Patient_ID': 'patient_id',\n",
    "    'Age': 'age',\n",
    "    'Gender': 'gender',\n",
    "    'Race': 'race',\n",
    "    'Average Sleep Duration (hrs)': 'avg_sleep_hours',\n",
    "    'Sleep Quality (1-10)': 'sleep_quality',\n",
    "    '% with Sleep Disturbances': 'sleep_disturbances_pct'\n",
    "}\n",
    "\n",
    "df_demo.rename(columns=rename_map, inplace=True)\n",
    "#saving the data to the cleaned_demographics.csv file \n",
    "df_demo.to_csv(\"cleaned_demographics.csv\", index=False)\n",
    "print(df_demo.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396851ab-d5aa-4405-889c-502ac9c2ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "combining cleaned_demographies and enriched patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39664562-662a-4cfe-8b1c-1d1a9fef2d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Merged Data Summary\n",
      "Total records: 309392\n",
      "Columns: ['patient_id', 'time', 'glucose', 'calories', 'heart_rate', 'steps', 'basal_rate', 'bolus_volume_delivered', 'carb_input', 'date', 'clock_time', 'hour', 'dayofweek', 'age', 'gender', 'race', 'avg_sleep_hours', 'sleep_quality', 'sleep_disturbances_pct']\n",
      "üß™ Sample rows:\n",
      "patient_id                time  glucose  calories  heart_rate  steps  basal_rate  bolus_volume_delivered  carb_input       date clock_time  hour dayofweek  age gender  race  avg_sleep_hours  sleep_quality  sleep_disturbances_pct\n",
      " HUPA0001P 2018-06-13 18:40:00    332.0    6.3595   82.322835   34.0    0.091667                     0.0         0.0 2018-06-13   18:40:00    18 Wednesday   34   Male Other              6.3            4.5                      80\n",
      " HUPA0001P 2018-06-13 18:45:00    326.0    7.7280   83.740157    0.0    0.091667                     0.0         0.0 2018-06-13   18:45:00    18 Wednesday   34   Male Other              6.3            4.5                      80\n",
      " HUPA0001P 2018-06-13 18:50:00    330.0    4.7495   80.525180    0.0    0.091667                     0.0         0.0 2018-06-13   18:50:00    18 Wednesday   34   Male Other              6.3            4.5                      80\n",
      " HUPA0001P 2018-06-13 18:55:00    324.0    6.3595   89.129032   20.0    0.091667                     0.0         0.0 2018-06-13   18:55:00    18 Wednesday   34   Male Other              6.3            4.5                      80\n",
      " HUPA0001P 2018-06-13 19:00:00    306.0    5.1520   92.495652    0.0    0.075000                     0.0         0.0 2018-06-13   19:00:00    19 Wednesday   34   Male Other              6.3            4.5                      80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 1: Load enriched patient data\n",
    "df_patients = pd.read_csv(\"final_patients_enriched.csv\")\n",
    "\n",
    "# Step 2: Load demographics data\n",
    "df_demograph = pd.read_csv(\"cleaned_demographics.csv\")\n",
    "\n",
    "# Step 3: Merge on patient_id\n",
    "df_merged = pd.merge(df_patients, df_demograph, on=\"patient_id\", how=\"left\")\n",
    "\n",
    "# Step 4: Preview merged data\n",
    "print(\"üîó Merged Data Summary\")\n",
    "print(f\"Total records: {len(df_merged)}\")\n",
    "print(f\"Columns: {df_merged.columns.tolist()}\")\n",
    "print(\"üß™ Sample rows:\")\n",
    "print(df_merged.head().to_string(index=False))\n",
    "\n",
    "# Step 5: Save merged version\n",
    "df_merged.to_csv(os.path.join(\"patients_data\", \"final_patients_full.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e6711dc-0f21-402b-948b-52fa816e283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ df_patients columns: ['patient_id', 'time', 'glucose', 'calories', 'heart_rate', 'steps', 'basal_rate', 'bolus_volume_delivered', 'carb_input', 'date', 'clock_time', 'hour', 'dayofweek']\n",
      "üß¨ df_demo columns: ['Patient_ID', 'Age', 'Gender', 'Race', 'Average Sleep Duration (hrs)', 'Sleep Quality (1-10)', '% with Sleep Disturbances']\n"
     ]
    }
   ],
   "source": [
    "print(\"üß¨ df_patients columns:\", df_patients.columns.tolist())\n",
    "print(\"üß¨ df_demo columns:\", df_demo.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5114a07-5a64-4aab-b08a-77174bdeea10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
